{
    "api_endpoint": "http://localhost:11434/api/generate",
    "model": "llama3",
    "supports_vision": false,
    "temperature": 0.7,
    "max_tokens": 1024,
    "request_format": {
      "prompt": "{prompt}",
      "model": "{model}",
      "temperature": 0.7
    },
    "response_field": "response"
  }